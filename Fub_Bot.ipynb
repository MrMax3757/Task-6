{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_from_directory, render_template\n",
        "from flask_cors import CORS\n",
        "from groq import Groq\n",
        "from elevenlabs.client import ElevenLabs\n",
        "from elevenlabs import VoiceSettings\n",
        "from dotenv import load_dotenv\n",
        "from transformers import pipeline\n",
        "import torch, os, base64, uuid, tempfile, requests, random\n",
        "\n",
        "# Setup\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "load_dotenv()\n",
        "\n",
        "# API keys\n",
        "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "eleven_labs = ElevenLabs(api_key=os.getenv(\"ELEVEN_API_KEY\"))\n",
        "GIPHY_API_KEY = os.getenv(\"GIPHY_API_KEY\")\n",
        "\n",
        "# Load Whisper model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "whisper_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\", device=device)\n",
        "\n",
        "# Funny, Clueless People-Pleaser Personality\n",
        "def get_roast_response(prompt):\n",
        "    res = groq_client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You're a clueless, overly excited people-pleaser who always tries to say the nicest \"\n",
        "                    \"and most hilarious things possible. You misunderstand everything in a charming and \"\n",
        "                    \"chaotic way. End each message with 'GIF:' and a fun GIF idea.\"\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=1.0,\n",
        "        max_tokens=250\n",
        "    )\n",
        "    return res.choices[0].message.content\n",
        "\n",
        "# Text-to-Speech\n",
        "def text_to_speech(text):\n",
        "    try:\n",
        "        response = eleven_labs.text_to_speech.convert(\n",
        "            voice_id=\"pNInz6obpgDQGcFmaJgB\",\n",
        "            text=text,\n",
        "            model_id=\"eleven_turbo_v2_5\",\n",
        "            output_format=\"mp3_22050_32\",\n",
        "            voice_settings=VoiceSettings(stability=0, similarity_boost=1, style=0, use_speaker_boost=True)\n",
        "        )\n",
        "        file = f\"temp_{uuid.uuid4()}.mp3\"\n",
        "        with open(file, \"wb\") as f:\n",
        "            for chunk in response:\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "        with open(file, \"rb\") as f:\n",
        "            encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "        os.remove(file)\n",
        "        return encoded\n",
        "    except Exception as e:\n",
        "        print(\"TTS error:\", e)\n",
        "        return None\n",
        "\n",
        "# Get GIF\n",
        "def fetch_gif(prompt):\n",
        "    try:\n",
        "        r = requests.get(\"https://api.giphy.com/v1/gifs/search\", params={\n",
        "            \"api_key\": GIPHY_API_KEY, \"q\": prompt, \"limit\": 10, \"rating\": \"r\"\n",
        "        }).json()\n",
        "        return random.choice(r[\"data\"])[\"images\"][\"original\"][\"url\"] if r[\"data\"] else \"\"\n",
        "    except:\n",
        "        return \"https://media.giphy.com/media/RBeddeaQ5Xo0E/giphy.gif\"\n",
        "\n",
        "# Parse roast and GIF\n",
        "def split_roast_and_gif(text):\n",
        "    if 'GIF:' in text:\n",
        "        roast, gif_prompt = text.split('GIF:', 1)\n",
        "        return roast.strip(), gif_prompt.strip()\n",
        "    return text, \"funny fail\"\n",
        "\n",
        "# Routes\n",
        "@app.route('/roast', methods=['POST'])\n",
        "def roast():\n",
        "    data = request.json\n",
        "    user_input = data.get(\"text\", \"\")\n",
        "    prompt = f\"Respond nicely and hilariously to this:\\n{user_input}\\nMake it confusing and chaotic in a sweet way. End with GIF: something fun.\"\n",
        "    full_response = get_roast_response(prompt)\n",
        "    roast, gif_prompt = split_roast_and_gif(full_response)\n",
        "    return jsonify({\n",
        "        \"roast\": roast,\n",
        "        \"gif\": fetch_gif(gif_prompt),\n",
        "        \"audio\": text_to_speech(roast)\n",
        "    })\n",
        "\n",
        "@app.route('/transcribe', methods=['POST'])\n",
        "def transcribe():\n",
        "    if 'audio' not in request.files:\n",
        "        return jsonify({'error': 'No audio file'}), 400\n",
        "    audio = request.files['audio']\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as f:\n",
        "        audio.save(f.name)\n",
        "        text = whisper_model(f.name)[\"text\"]\n",
        "    os.unlink(f.name)\n",
        "    return jsonify({'transcription': text})\n",
        "\n",
        "@app.route('/favicon.ico')\n",
        "def favicon():\n",
        "    return send_from_directory(os.path.join(app.root_path, 'static'),\n",
        "                               'favicon.ico', mimetype='image/vnd.microsoft.icon')\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "XbhYKuBtUYNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}